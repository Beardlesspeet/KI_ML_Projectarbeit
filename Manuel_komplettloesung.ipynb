{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\oache\\Desktop\\KI_ML\\Code\\Manuel_komplettloesung.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oache/Desktop/KI_ML/Code/Manuel_komplettloesung.ipynb#ch0000002?line=3'>4</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oache/Desktop/KI_ML/Code/Manuel_komplettloesung.ipynb#ch0000002?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mshapely\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeometry\u001b[39;00m \u001b[39mimport\u001b[39;00m Point\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/oache/Desktop/KI_ML/Code/Manuel_komplettloesung.ipynb#ch0000002?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oache/Desktop/KI_ML/Code/Manuel_komplettloesung.ipynb#ch0000002?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m \u001b[39mimport\u001b[39;00m GeoDataFrame\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oache/Desktop/KI_ML/Code/Manuel_komplettloesung.ipynb#ch0000002?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'C:/Users/oache/Desktop/KI_ML/vehicles/vehicles.csv'\n",
    "#url= 'C:/Users/nicof/OneDrive/Dokumente/FH-M체nchen/KI\\Modularbeit/archive/vehicles.csv'\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (df.groupby(['manufacturer'],as_index = False).count().sort_values('price', ascending = False))['manufacturer'].tolist()\n",
    "y = (df.groupby(['manufacturer'],as_index = False).count().sort_values('price', ascending = False))['price'].tolist()\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.xticks(rotation = 90)\n",
    "plt.bar(x, y, width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information about the categorical variables\n",
    "\n",
    "print(df[\"paint_color\"].unique())\n",
    "print(df[\"condition\"].unique())\n",
    "print(df[\"type\"].unique())\n",
    "print(df[\"fuel\"].unique())\n",
    "print(df[\"cylinders\"].unique())\n",
    "print(df[\"title_status\"].unique())\n",
    "print(df[\"type\"].unique())\n",
    "print(df[\"drive\"].unique())\n",
    "print(df[\"transmission\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a lot of locations that don't make sense (i.e. on Antarctica or in the ocean) \n",
    "#User can drop a pin anywhere in the world => lat & long values are unreliable\n",
    "#Use 'state' and/or 'region' instead of lat & long for location\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df['long'], df['lat'])]\n",
    "gdf = GeoDataFrame(df, geometry=geometry)   \n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "gdf.plot(ax=world.plot(figsize=(10, 6)), marker='o', color='red', markersize=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that don't add any value to our analysis\n",
    "\n",
    "df.drop(['Unnamed: 0', 'id', 'url', 'region_url', 'lat', 'long', 'VIN', 'image_url',\n",
    "         'description', 'geometry', 'posting_date'], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only 'clean' cars & missing values\n",
    "#missing, parts only, etc. cars don't fit the goal of our analysis\n",
    "\n",
    "df = df[((df['title_status'] != 'missing') & (df['title_status'] != 'parts only') \n",
    "    & (df['title_status'] != 'salvage') & (df['title_status'] != 'rebuilt')\n",
    "   & (df['title_status'] != 'lien'))]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unrealistically over-/underpriced cars (over $500k or under $100)\n",
    "#sometimes prices are $0 or $123456789 because the owner wants to agree on the price in person\n",
    "\n",
    "df = df[((df['price'] < 500000) & (df['price'] > 100))]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_year = 1960\n",
    "x = (df.groupby(['year'],as_index = False).count())['year'].tolist()\n",
    "y = (df.groupby(['year'],as_index = False).count())['price'].tolist()\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.bar(x, y, width=1)\n",
    "plt.axvline(starting_year, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete cars built before 1960 (outliers)\n",
    "\n",
    "df = df[df['year'] > 1960]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete top 1% of odometer values (outliers)\n",
    "\n",
    "top1 = np.nanpercentile(df['odometer'], 99)\n",
    "print('the top 1% mileage is', top1, 'miles')\n",
    "df = df[df['odometer'] < top1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size is perfect multicollinear with car model => drop size column\n",
    "\n",
    "df.drop('size', axis = 1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unknown fuel, transmission and title_status instances\n",
    "\n",
    "df.dropna(subset = ['fuel', 'transmission', 'title_status'], axis = 0, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all instances with unknown manufacturer\n",
    "\n",
    "df = df[~df['manufacturer'].isnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all instances with unknown model\n",
    "\n",
    "df = df[~df['model'].isnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing condition values with 'not specified'\n",
    "\n",
    "df['condition'].fillna('not specified', inplace = True)\n",
    "df['condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing color with 'unknown'\n",
    "\n",
    "df['paint_color'].fillna('unknown', inplace = True)\n",
    "df['paint_color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first word is most important for 'model': many car model categories refer to the same model but are written differently \n",
    "#(i.e. 'f150 good condition' and 'F - 150 four wheel drive' refer to the same model: f150)\n",
    "#=> keep only first word and remove spaces, special characters, uppercase letters, etc.\n",
    "\n",
    "#delete instances with a model that appears less than 150 times => reduce amount of categories by omitting uncommon types\n",
    "\n",
    "model_list = df['model'].tolist()\n",
    "model_list = map(str, model_list)\n",
    "model_list = [x.lower().strip() for x in model_list]\n",
    "my_list = [car_model.split()[0] for car_model in model_list]\n",
    "my_list = [x.replace(' ', '').replace('-', '').replace('/', '') for x in my_list]\n",
    "\n",
    "df['car_model'] = my_list\n",
    "df['car_model'] = df['manufacturer'] + \" \" + df['car_model']\n",
    "\n",
    "new_car_models = (df.groupby(['car_model'], as_index= False).count())[['manufacturer', 'car_model', 'price']]\n",
    "new_car_models = new_car_models.rename(columns={'price': 'count'})\n",
    "only_common_models = new_car_models[new_car_models['count'] > 150]\n",
    "\n",
    "print('total car models: ', len(new_car_models['count']))\n",
    "print('remaining car models: ', len(only_common_models['count']))\n",
    "print('decreasing ', round((1-len(only_common_models['count'])/len(new_car_models['count'])) * 100, 2),'% of the number of car models')\n",
    "print()\n",
    "print('total instances: ', len(df['price']))\n",
    "print('remaining instances: ', sum(only_common_models['count']))\n",
    "print('removing ', round((1-sum(only_common_models['count'])/len(df['price'])) * 100, 2),'% of the instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#150 seems like the reasonable choice w.r.t. trade-off reducing categories vs keeping enough data\n",
    "\n",
    "removed_models_list = []\n",
    "removed_instances_list = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "    only_common_models_v2 = new_car_models[new_car_models['count']>i]\n",
    "    models_removed = 1-len(only_common_models_v2['count'])/len(new_car_models['count'])\n",
    "    instances_removed = 1-sum(only_common_models_v2['count'])/len(df['price'])\n",
    "    \n",
    "    removed_models_list.append(models_removed)\n",
    "    removed_instances_list.append(instances_removed)\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.plot(removed_models_list, label = 'Percentage of unqiue models removed')\n",
    "plt.plot(removed_instances_list, label = 'Percentage of instances removed')\n",
    "plt.axvline(150 , color = 'red', label = 'Cut-off')\n",
    "plt.ylabel('Percentage Remaining')\n",
    "plt.xlabel('Car model frequency cut-off')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#committing car model cleaning to original dataframe\n",
    "\n",
    "df = df[df['car_model'].isin(only_common_models['car_model'].tolist())]\n",
    "df.drop('model', axis = 1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing number of cylinders with median of car model & delete 'other'\n",
    "\n",
    "df = df[df['cylinders'] != 'other']\n",
    "dftest = df.copy()\n",
    "test = df[df['cylinders'].notnull()].copy()\n",
    "test['cylinders'] = [int(cyl.split()[0]) for cyl in test['cylinders']]\n",
    "med = test.groupby('car_model')['cylinders'].median()\n",
    "merged = pd.merge(dftest, med, on = 'car_model', how = 'left')\n",
    "merged['cylinders_y'].fillna(med.median(), inplace = True)\n",
    "merged['cylinders_x'].fillna(merged['cylinders_y'], inplace = True)\n",
    "\n",
    "li = []\n",
    "for cyl in merged['cylinders_x']:\n",
    "    if type(cyl) == str:\n",
    "        li.append(cyl)\n",
    "    else:\n",
    "        li.append(str(int(cyl)) + \" cylinders\")\n",
    "\n",
    "df['cylinders'] = li\n",
    "df['cylinders'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace drive with mode drive of car model\n",
    "\n",
    "dftest = df.copy()\n",
    "test = df[df['drive'].notnull()].copy()\n",
    "mode = test.groupby('car_model')['drive'].agg(pd.Series.mode)\n",
    "merged = pd.merge(dftest, mode, on = 'car_model', how = 'left')\n",
    "merged['drive_x'].fillna(merged['drive_y'], inplace = True)\n",
    "\n",
    "df['drive'] = merged['drive_x'].tolist()\n",
    "df['drive'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the missing values are handled\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of overpriced cars: overpriced = more than 3 times the average for this model\n",
    "\n",
    "df = df[df['price'] < (3 * df.groupby('car_model')['price'].transform('mean'))]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region & state contain same information (certain region is always in the same state)\n",
    "\n",
    "df.drop('region', axis = 1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates model as defined in 'reg' and returns test & train evaluation metrics\n",
    "#default is 80/20 train-test split: industry standard\n",
    "\n",
    "def updateModel(datafr, test_percentage = 0.2, seed = 7):\n",
    "    \n",
    "    #train-test split\n",
    "    X = datafr.drop('price', axis = 1)\n",
    "    y = datafr['price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_percentage, random_state = seed)\n",
    "    X_train = pd.get_dummies(X_train, drop_first = True)\n",
    "    X_test = pd.get_dummies(X_test, drop_first = True)\n",
    "    \n",
    "    #feature scaling\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    #making model + predicting\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred_test = reg.predict(X_test)\n",
    "    y_pred_train = reg.predict(X_train)\n",
    "    \n",
    "    #computing test & train metrics\n",
    "    test_metrics = {'r2': round(r2_score(y_test, y_pred_test) * 100, 2),\n",
    "           'mae': round(mean_absolute_error(y_test, y_pred_test), 2),\n",
    "           'mse': round(mean_squared_error(y_test, y_pred_test), 2),\n",
    "           'mape': round(mean_absolute_percentage_error(y_test, y_pred_test) * 100, 2)\n",
    "           }\n",
    "    train_metrics = {'r2': round(r2_score(y_train, y_pred_train) * 100, 2),\n",
    "           'mae': round(mean_absolute_error(y_train, y_pred_train), 2),\n",
    "           'mse': round(mean_squared_error(y_train, y_pred_train), 2),\n",
    "           'mape': round(mean_absolute_percentage_error(y_train, y_pred_train) * 100, 2)\n",
    "           }\n",
    "    \n",
    "    return {'test_metrics': test_metrics,\n",
    "            'train_metrics': train_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates model as defined in 'reg' and returns k fold cross validation metrics\n",
    "#default is 5-fold CV: industry standard & default scoring is MAE because of easy interpretation\n",
    "\n",
    "def get_kCVscores(datafr, k = 5, scoring = 'neg_mean_absolute_error'):\n",
    "    X = datafr.drop('price', axis = 1)\n",
    "    X = pd.get_dummies(X, drop_first = True)\n",
    "    y = datafr['price']\n",
    "    return (cross_val_score(reg, X, y, cv = k, scoring = scoring) * (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-means clustering function\n",
    "def k_means_clustering(datafr, k):\n",
    "    df_to_return = datafr.copy()\n",
    "    df_with_dummies = pd.get_dummies(datafr, drop_first = True)\n",
    "    km = KMeans(n_clusters = k)\n",
    "    df_to_return['cluster'] = km.fit_predict(df_with_dummies)\n",
    "    \n",
    "    return df_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial linear regression model\n",
    "\n",
    "init_metrics = updateModel(df)\n",
    "def print_metrics(metrics):\n",
    "    print('test performance:', metrics['test_metrics'])\n",
    "    print('initial test performance:', init_metrics['test_metrics'])\n",
    "    print()\n",
    "    print('train performance:', metrics['train_metrics'])\n",
    "    print('initial train performance:', init_metrics['train_metrics'])\n",
    "    print()\n",
    "    print('change in test MAE:', round((init_metrics['test_metrics']['mae'] - metrics['test_metrics']['mae']) / \n",
    "      (init_metrics['test_metrics']['mae']) * 100, 2), '%')\n",
    "print_metrics(init_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_dict = {\"state\": [\"al\",\"ak\",\"az\",\"ar\",\"ca\",\"co\",\"ct\",\"de\",\"dc\",\"fl\",\"ga\",\"hi\",\"id\",\"il\",\"in\",\"ia\",\"ks\",\"ky\",\"la\",\"me\",\"md\",\"ma\",\"mi\",\"mn\",\"ms\",\"mo\",\"mt\",\"ne\",\"nv\",\"nh\",\"nj\",\"nm\",\"ny\",\"nc\",\"nd\",\"oh\",\"ok\",\"or\",\"pa\",\"ri\",\"sc\",\"sd\",\"tn\",\"tx\",\"ut\",\"vt\",\"va\",\"wa\",\"wv\",\"wi\",\"wy\"], \n",
    "         \"region\": [\"south\",\"west\",\"west\",\"south\",\"west\",\"west\",\"north-east\",\"south\",\"south\",\"south\",\"south\",\"west\",\"west\",\"mid-west\",\"mid-west\",\"mid-west\",\"mid-west\",\"south\",\"south\",\"north-east\",\"south\",\"north-east\",\"mid-west\",\"mid-west\",\"south\",\"mid-west\",\"west\",\"mid-west\",\"west\",\"north-east\",\"north-east\",\"west\",\"north-east\",\"south\",\"mid-west\",\"mid-west\",\"south\",\"west\",\"north-east\",\"north-east\",\"south\",\"mid-west\",\"south\",\"south\",\"west\",\"north-east\",\"south\",\"west\",\"south\",\"mid-west\",\"west\"]}\n",
    "dfState = pd.merge(df, pd.DataFrame(regions_dict), on = 'state', how = 'left').drop('state', axis = 1)\n",
    "dfState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new metrics\n",
    "\n",
    "binned_states_metrics = updateModel(dfState)\n",
    "print_metrics(binned_states_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDropState = df.drop('state', axis = 1)\n",
    "dfDropState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new metrics\n",
    "\n",
    "drop_state_metrics = updateModel(dfDropState)\n",
    "print_metrics(drop_state_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoCarModel = df.drop('car_model', axis = 1)\n",
    "dfNoCarModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_car_model_metrics = updateModel(dfNoCarModel)\n",
    "print_metrics(no_car_model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBinnedYear = df.copy()\n",
    "dfBinnedYear['year'] = pd.cut(df['year'], 3, labels = ['vintage', 'medium age', 'recent'])\n",
    "dfBinnedYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_year_metrics = updateModel(dfBinnedYear)\n",
    "print_metrics(binned_year_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAge = df.copy()\n",
    "dfAge['age'] = [2021 - x for x in df['year'].tolist()]\n",
    "dfAge.drop('year', axis=1, inplace = True)\n",
    "dfAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_metrics = updateModel(dfAge)\n",
    "print_metrics(age_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can clearly see a U-shaped pricing behavior in function of car age\n",
    "#in addition, we can identify age categories with similar pricing behavior\n",
    "\n",
    "dfAgeCat = dfAge.copy()\n",
    "thresholds = [50,40,30,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1]\n",
    "groups = ['over 50','40-49','30-39','15-29','14','13','12','11','10','9','8','7','6','5','4','3','2','1']\n",
    "\n",
    "x = (dfAgeCat.groupby(['age'],as_index = False).mean())['age'].tolist()\n",
    "y = (dfAgeCat.groupby(['age'],as_index = False).mean())['price'].tolist()\n",
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.ylabel('Mean price')\n",
    "plt.xlabel('Age (years)')\n",
    "plt.bar(x, y, width=1)\n",
    "for t in thresholds:\n",
    "    plt.axvline(t-0.5, color = 'red')\n",
    "\n",
    "plt.axvline(-0.5, color = 'red')\n",
    "plt.axvline(60.5, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(dfAgeCat['age'].tolist())\n",
    "for t in thresholds:\n",
    "    prevArr = arr\n",
    "    arr = np.where(prevArr >= t, -t, prevArr)\n",
    "    \n",
    "prevArr = arr\n",
    "dfAgeCat['age_group'] = np.where(prevArr >= 0, 'new', prevArr).tolist()\n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "     toReplace = str(float(-thresholds[i]))\n",
    "     dfAgeCat['age_group'].replace(toReplace, groups[i], inplace =  True)\n",
    "\n",
    "dfAgeCat.drop('age', axis=1, inplace=True)    \n",
    "print(dfAgeCat['age_group'].unique())\n",
    "dfAgeCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cat_metrics = updateModel(dfAgeCat)\n",
    "print_metrics(age_cat_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlots = dfAge.copy()\n",
    "for feat in dfAgeCat.drop(['price','odometer','car_model','age_group'], axis = 1).columns:\n",
    "    print(feat)\n",
    "    x = (dfPlots.groupby(feat, as_index = False).mean()).sort_values(by = ['price'])[feat]\n",
    "    y = (dfPlots.groupby(feat, as_index = False).mean()).sort_values(by = ['price'])['price']\n",
    "    fig = plt.figure(figsize=[10,5])\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel('Mean price')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.bar(x, y, width=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCondition = df.copy()\n",
    "\n",
    "dfCondition['condition'].replace('new', 6, inplace =  True)\n",
    "dfCondition['condition'].replace('like new', 5, inplace =  True)\n",
    "dfCondition['condition'].replace('excellent', 4, inplace =  True)\n",
    "dfCondition['condition'].replace('good', 3, inplace =  True)\n",
    "dfCondition['condition'].replace('fair', 2, inplace =  True)\n",
    "dfCondition['condition'].replace('salvage', 1, inplace =  True)\n",
    "dfCondition['condition'].replace('not specified', 3, inplace =  True)\n",
    "\n",
    "dfCondition['condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_metrics = updateModel(dfCondition)\n",
    "print_metrics(condition_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfColors = df.copy()\n",
    "dfColors['paint_color'].replace(['unknown', 'blue', 'silver', 'grey', 'green', 'custom', 'yellow', 'brown', 'purple'], 'other_colors', inplace =  True)\n",
    "dfColors['paint_color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_metrics = updateModel(dfColors)\n",
    "print_metrics(color_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMPY = dfAge.copy()\n",
    "MPY_temp = []\n",
    "\n",
    "dfMPY['miles_per_year'] = [dfMPY['odometer'][i]/(dfMPY['age'][i]+0.001) for i in dfMPY.index.tolist()]\n",
    "dfMPY.drop(['odometer', 'age'], axis=1, inplace=True)\n",
    "dfMPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPY_metrics = updateModel(dfMPY)\n",
    "print_metrics(MPY_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoCyl = df.drop('cylinders', axis = 1)\n",
    "dfNoCyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cyl_metrics = updateModel(dfNoCyl)\n",
    "print_metrics(no_cyl_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoType = df.drop('type', axis = 1)\n",
    "dfNoType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_type_metrics = updateModel(dfNoType)\n",
    "print_metrics(no_type_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only creating age_groups had a positive impact on performance\n",
    "#dropping 'type' and binning 'state' into regions had no real impact on performance but made the model more interpretable\n",
    "\n",
    "df = dfAgeCat\n",
    "df = pd.merge(df, pd.DataFrame(regions_dict), on = 'state', how = 'left').drop('state', axis = 1)\n",
    "df.drop('type', axis = 1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression model on the feature engineered df\n",
    "\n",
    "initLR = updateModel(df)\n",
    "print_metrics(initLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(df, drop_first = True).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = reg.coef_\n",
    "\n",
    "temp = pd.DataFrame({'feat n째': [x for x in range(len(importance))],'importance': importance})\n",
    "temp = temp.sort_values('importance')\n",
    "worst10 = temp[:10]\n",
    "best10 = temp[-10:]\n",
    "best10['feat'] = cols[best10['feat n째']]\n",
    "worst10['feat'] = cols[worst10['feat n째']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation = 90)\n",
    "plt.bar(best10['feat'], best10['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation = 90)\n",
    "plt.bar(worst10['feat'], worst10['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20-tree RF\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators = 20, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initRF = updateModel(df)\n",
    "print_metrics(initRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcv = get_kCVscores(df)\n",
    "kcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cross validated MAE mean:', kcv.mean())\n",
    "print('Cross validated MAE standard deviation:', kcv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100-tree RF\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators = 100, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init100RF = updateModel(df)\n",
    "print_metrics(init100RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(n_estimators = 50, learning_rate = 0.1, max_depth = 1, random_state = 7, loss = 'ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initBoost = updateModel(df)\n",
    "print_metrics(initBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initNN = updateModel(df)\n",
    "print_metrics(initNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow plot values\n",
    "distortions = []\n",
    "df_with_dummies = pd.get_dummies(df.copy(), drop_first = True)\n",
    "\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(df_with_dummies)\n",
    "    distortions.append(km.inertia_)\n",
    "\n",
    "#Plotting\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('Elbow Method to determine the optimal k value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering_k2 = k_means_clustering(df, 2)\n",
    "df_clustering_k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering_k3 = k_means_clustering(df, 3)\n",
    "df_clustering_k3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df_clustering_k2, drop_first = True).groupby(['cluster']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df_clustering_k3, drop_first = True).groupby(['cluster']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use = pd.get_dummies(df_clustering_k2, drop_first = True)\n",
    "k = 2\n",
    "print('For k = ', k)\n",
    "\n",
    "list_of_results = []\n",
    "for i in range(k):\n",
    "    cluster_df = (df_to_use[df_to_use['cluster']==i]).copy()\n",
    "    res = updateModel(cluster_df)\n",
    "    print_metrics(res)\n",
    "    list_of_results.append(res)\n",
    "\n",
    "clust_k2_LR_results = list_of_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use = pd.get_dummies(df_clustering_k3, drop_first = True)\n",
    "k = 3\n",
    "print('For k = ', k)\n",
    "\n",
    "list_of_results = []\n",
    "for i in range(k):\n",
    "    cluster_df = (df_to_use[df_to_use['cluster']==i]).copy()\n",
    "    res = updateModel(cluster_df)\n",
    "    print_metrics(res)\n",
    "    list_of_results.append(res)\n",
    "\n",
    "clust_k3_LR_results = list_of_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators = 20, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use = pd.get_dummies(df_clustering_k2, drop_first = True)\n",
    "k = 2\n",
    "print('For k = ', k)\n",
    "\n",
    "list_of_results = []\n",
    "for i in range(k):\n",
    "    cluster_df = (df_to_use[df_to_use['cluster']==i]).copy()\n",
    "    res = updateModel(cluster_df)\n",
    "    print_metrics(res)\n",
    "    list_of_results.append(res)\n",
    "\n",
    "clust_k2_RF_results = list_of_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(initRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = df_clustering_k2.copy()\n",
    "dfFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPerformance = clust_k2_RF_results\n",
    "print('Cluster 1:')\n",
    "print_metrics(finalPerformance[0])\n",
    "print()\n",
    "print('Cluster 2:')\n",
    "print_metrics(finalPerformance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = reg\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalClusters = df_clustering_k2.copy()\n",
    "pd.get_dummies(finalClusters, drop_first = True).groupby(['cluster']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal.to_csv('final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d50220305086dde7714464d39eb812e6992001230edb4d06ec4afb2ffb1c28c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
